---
layout: standard
<!-- title: Talks and Presentations -->
list_title: ' '
permalink: /talks/
---
<!-- <h1> Presentations</h1>
<p> workshops, seminars and talks </p> -->

<!-- <hr> -->
<h1>Teaching</h1>
<hr>
<div class="grid_">
  <div class="talk-grid-container">
    <!-- <div> -->
  <!-- <div class="talk_link">Presentation</div> -->
<!-- <div class="talk_link">  <a href ="https://eh.uc.edu/support_files/erc/2020/pdf/posters/Oyindamola_Omotuyi.pdf" target="_blank"> Code </a> </div> -->
<!-- <div class="talk_link1">  <a href ="https://eh.uc.edu/support_files/erc/2020/pdf/posters/Oyindamola_Omotuyi.pdf" target="_blank"> Poster </a> </div> -->

  <div class="talk_details">
  <h2 class="talk_title">Intelligent and Autonomous Mobile Robots</h2>

  <p class="talk_role">Spring 2020</p>


   </div>

  </div>
  <div class="talk_description"><p>
    MECH 7020 is a graduate-level introduction to algorithmic and software tools that allow mobile robots to operate autonomously
    in unknown and dynamic environments taught by <a href="https://researchdirectory.uc.edu/p/kumarmu" target="_blank"</a>
      Professor Manish Kumar</a>. The course broadly covers methods and tools for three areas of robotics:
    state estimation, localization and mapping, and motion planning and control. A team of two other students
    and I pioneered the course curriculum design because it was the first time it would be offered.
    As the teaching assistant, I created all the programming assignments, hardware checklists, and the
    final project. I also prepared the lecture materials and taught ROS/Gazebo to the students to enable
    them to implement the concepts in the class. Finally, I tutored and supervised the students on how to
    build and control the <a href="https://github.com/NVIDIA-AI-IOT/jetbot" target="_blank">NVIDIA Jetson Nano robots</a>. Because of COVID, we switch to a simulation-based project
    which was utilizing EKF-SLAM with AprilTags Landmarks on Turtlebot3 in ROS/Gazebo.

 </p></div>
</div>
<br>

<br>
<h1>Workshops</h1>
<hr>
<div class="grid_">
  <div class="talk-grid-container">
    <!-- <div> -->
  <!-- <div class="talk_link">Presentation</div> -->
<div class="talk_link">  <a href ="https://eh.uc.edu/support_files/erc/2020/pdf/posters/Oyindamola_Omotuyi.pdf" target="_blank"> Poster </a> </div>
<!-- <div class="talk_link1">  <a href ="https://eh.uc.edu/support_files/erc/2020/pdf/posters/Oyindamola_Omotuyi.pdf" target="_blank"> Poster </a> </div> -->

  <div class="talk_details">
  <h2 class="talk_title">Real-Time Automated Vehicle Crash Detection and Reporting System</h2>

  <p class="talk_role">21st Annual Pilot Research Project Symposium</p>

   </div>

  </div>


  <div class="talk_description"><p>
    According to World Health Organization, the number of deaths caused by road
  traffic crashes is approximately 1.35 million people around the world each year,
  and between 20 and 50 million suffer people with non-fatal injuries each year
  due to vehicular crashes. Delays in detecting and providing care for those involved in a road traffic crash
increase the severity of injuries. A faster rescue response has the potential to not only save lives but also result
in faster clearing of accidents and lesser congestion. The motivation behind the proposed study is to minimize the
  response time of the authorities, including first responders and
  firefighters for restoring the traffic operations after vehicular crashes
  and in the process save lives.The main objective of this project is to develop a low-cost automated vehicle crash reporting video analytics
  software which can detect and report vehicular crashes at the traffic intersections.
  </p></div>
</div>
<br>
<div class="grid_">
  <div class="talk-grid-container">
    <!-- <div> -->
  <div class="talk_link"> <a href ="https://aiaa-istc.github.io/prior_workshops/2019_IS_Workshop.html" target="_blank"> AIAA</a></div>
  <div class="talk_details">
  <h2 class="talk_title">Autonomous Mobile Robot Localization and
Navigation system using camera and inertial measurement unit (IMU) in an indoor environment</h2>

  <p class="talk_role">Role: Co-Presenter at AIAA Intelligent Systems Workshop, July 2019 </p>

   </div>

  </div>

    <div class="talk_description"><p>
    I co-presented the preliminary results of our work at the conference. Authors:  Kumat Ashwin, Omotuyi Oyindamola, Deshpande A. M., Calabrese Nate, Kumar Manish
    </p></div>
</div>
<br>


<br>
<h1>Talks</h1>
<hr>
<div class="grid_">
  <div class="talk-grid-container">
    <!-- <div> -->
  <div class="talk_link"> <a href ="https://eh.uc.edu/support_files/erc/2020/pdf/posters/Oyindamola_Omotuyi.pdf" target="_blank"> NVIDIA</a></div>
  <div class="talk_details">
  <h2 class="talk_title">NVIDIA Emerging Chapters Developers Meetup March 21, 2022</h2>

  <p class="talk_role">Role: Presenter </p>


   </div>

  </div>
  <div class="talk_description"><p>
  I was one of the presenters speaking to a large community of developers, especially in emerging markets. I spoke on
  my career journey and internship experience with NVIDIA.
  </p></div>
</div>


<br>
<div class="grid_">
  <div class="talk-grid-container">
    <!-- <div> -->
  <div class="talk_link"> <a href ="/assets/laser.pdf" target="_blank">PDF</a></div>
  <div class="talk_details">
  <h2 class="talk_title">Laser-Based EKF Localization on TurtleBot3 Robot</h2>

  <p class="talk_role">Role: Presenter at the 44th Dayton-Cincinnati Aerospace Sciences Symposium. March 2019. </p>


   </div>

  </div>
  <div class="talk_description"><p>
    This project presents a technique on the localization of a ground robot using the Extended Kalman Filter (EKF) with
  the use of a Light Detection and Ranging (Lidar) sensor. The use
    of EKF in localizing robots has been highly successful when
    working with small maps for many years. The goal of this project
    was to design and implement an algorithm which would replicate
    what has already been done using Python, ROS and Gazebo. This
    software environment was chosen because of its widespread use in
    industry and its ability to enable a quick transition between
    hardware and simulation. The simulation was based on the
    TurtleBot3 Burger platform. This platform was equipped with a
    360 Laser Distance Sensor LDS-01.
  </p></div>
</div>
<br>


<br>
